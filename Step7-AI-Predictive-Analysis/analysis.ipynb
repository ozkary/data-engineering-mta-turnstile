{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "import pandas as pd     \n",
    "import numpy as np\n",
    "# import plotly.figure_factory as plotly_ff\n",
    "# import plotly.express as plotly_x\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from scipy.stats import pearsonr\n",
    "import google.cloud.bigquery as dw\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "> Data analysis is the practice of exploring data and understanding its meaning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the project and database\n",
    "PROJECT = os.getenv('GOOGLE_PROJECT_NAME')\n",
    "DATASET = 'mta_data'\n",
    "\n",
    "# using the bigquery client library \n",
    "client = dw.Client()\n",
    "# set a reference to the database\n",
    "dataset_ref = client.dataset(DATASET, project=PROJECT)\n",
    "\n",
    "# define a run query function\n",
    "def run_query(sql):\n",
    "    query = client.query(sql)\n",
    "    return query.to_dataframe()\n",
    "\n",
    "# read records from n days ago\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# set a variable to the current date - n days\n",
    "last_month = datetime.today() - timedelta(days=90)\n",
    "date_value = last_month.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT station_name, booth_name, created_dt, entries, exits\n",
      "FROM `ozkary-de-101.mta_data.rpt_turnstile` \n",
      "WHERE created_dt >= '2024-02-10'\n",
      "LIMIT 100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sql = \"\"\"\n",
    "SELECT station_name, booth_name, created_dt, entries, exits\n",
    "FROM `{}.{}.rpt_turnstile` \n",
    "WHERE created_dt >= '{}'\n",
    "LIMIT 100000\n",
    "\"\"\".format(PROJECT, DATASET, date_value)\n",
    "df = run_query(sql)\n",
    "print(sql)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the CSV file if do not have access to a data warehouse\n",
    "\n",
    "> The file path is defined already in the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   station_name booth_name                created_dt  entries     exits\n",
      "0  ASTORIA BLVD       R514 2024-02-20 03:00:00+00:00  7112558  12965593\n",
      "1  ASTORIA BLVD       R514 2024-02-20 19:00:00+00:00  7112994  12966073\n",
      "2  ASTORIA BLVD       R514 2024-02-20 15:00:00+00:00  7112924  12965738\n",
      "3  ASTORIA BLVD       R514 2024-02-20 23:00:00+00:00  7113012  12966274\n",
      "4  ASTORIA BLVD       R514 2024-02-20 07:00:00+00:00  7112603  12965603\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype              \n",
      "---  ------        --------------   -----              \n",
      " 0   station_name  100000 non-null  object             \n",
      " 1   booth_name    100000 non-null  object             \n",
      " 2   created_dt    100000 non-null  datetime64[ns, UTC]\n",
      " 3   entries       100000 non-null  Int64              \n",
      " 4   exits         100000 non-null  Int64              \n",
      "dtypes: Int64(2), datetime64[ns, UTC](1), object(2)\n",
      "memory usage: 4.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entries</th>\n",
       "      <th>exits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>35967847.55507</td>\n",
       "      <td>29023910.22642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>202634658.343456</td>\n",
       "      <td>182748138.301513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>255560.5</td>\n",
       "      <td>173686.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1182822.0</td>\n",
       "      <td>874765.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5294468.0</td>\n",
       "      <td>3640540.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2147110438.0</td>\n",
       "      <td>2120902559.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                entries             exits\n",
       "count          100000.0          100000.0\n",
       "mean     35967847.55507    29023910.22642\n",
       "std    202634658.343456  182748138.301513\n",
       "min                 0.0               0.0\n",
       "25%            255560.5          173686.0\n",
       "50%           1182822.0          874765.0\n",
       "75%           5294468.0        3640540.25\n",
       "max        2147110438.0      2120902559.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv('./analysis_data.csv', iterator=False)\n",
    "print(df.head())\n",
    "\n",
    "# Display basic information about the dataset\n",
    "df.info()\n",
    "\n",
    "# Get summary statistics of numeric columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis - Profiling\n",
    "\n",
    "> Data profiling is the process to identify the data types, dimensions, measures, and quantitative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_name</th>\n",
       "      <th>booth_name</th>\n",
       "      <th>created_dt</th>\n",
       "      <th>entries</th>\n",
       "      <th>exits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29184</th>\n",
       "      <td>CORTLANDT ST</td>\n",
       "      <td>A052</td>\n",
       "      <td>2024-02-20 04:00:00+00:00</td>\n",
       "      <td>13671</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15202</th>\n",
       "      <td>8 ST-NYU</td>\n",
       "      <td>A038</td>\n",
       "      <td>2024-02-20 19:00:00+00:00</td>\n",
       "      <td>452161</td>\n",
       "      <td>174008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82030</th>\n",
       "      <td>JUNIUS ST</td>\n",
       "      <td>R630</td>\n",
       "      <td>2024-02-14 15:00:00+00:00</td>\n",
       "      <td>479157</td>\n",
       "      <td>3012643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91624</th>\n",
       "      <td>ATL AV-BARCLAY</td>\n",
       "      <td>R610</td>\n",
       "      <td>2024-02-14 21:30:00+00:00</td>\n",
       "      <td>7467</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75087</th>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>TRAM2</td>\n",
       "      <td>2024-02-14 16:00:00+00:00</td>\n",
       "      <td>1957415</td>\n",
       "      <td>49318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48763</th>\n",
       "      <td>1 AV</td>\n",
       "      <td>H007</td>\n",
       "      <td>2024-02-15 23:00:00+00:00</td>\n",
       "      <td>10529946</td>\n",
       "      <td>348461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97711</th>\n",
       "      <td>W 4 ST-WASH SQ</td>\n",
       "      <td>N083</td>\n",
       "      <td>2024-02-14 16:00:00+00:00</td>\n",
       "      <td>1502530</td>\n",
       "      <td>4265685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66569</th>\n",
       "      <td>FORDHAM RD</td>\n",
       "      <td>N218</td>\n",
       "      <td>2024-02-15 15:00:00+00:00</td>\n",
       "      <td>398445</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>111 ST</td>\n",
       "      <td>R530</td>\n",
       "      <td>2024-02-20 23:00:00+00:00</td>\n",
       "      <td>19238242</td>\n",
       "      <td>13074183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52327</th>\n",
       "      <td>23 ST</td>\n",
       "      <td>A031</td>\n",
       "      <td>2024-02-15 07:00:00+00:00</td>\n",
       "      <td>569459</td>\n",
       "      <td>1294536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         station_name booth_name                created_dt   entries     exits\n",
       "29184    CORTLANDT ST       A052 2024-02-20 04:00:00+00:00     13671         0\n",
       "15202        8 ST-NYU       A038 2024-02-20 19:00:00+00:00    452161    174008\n",
       "82030       JUNIUS ST       R630 2024-02-14 15:00:00+00:00    479157   3012643\n",
       "91624  ATL AV-BARCLAY       R610 2024-02-14 21:30:00+00:00      7467         0\n",
       "75087   RIT-ROOSEVELT      TRAM2 2024-02-14 16:00:00+00:00   1957415     49318\n",
       "48763            1 AV       H007 2024-02-15 23:00:00+00:00  10529946    348461\n",
       "97711  W 4 ST-WASH SQ       N083 2024-02-14 16:00:00+00:00   1502530   4265685\n",
       "66569      FORDHAM RD       N218 2024-02-15 15:00:00+00:00    398445         0\n",
       "2132           111 ST       R530 2024-02-20 23:00:00+00:00  19238242  13074183\n",
       "52327           23 ST       A031 2024-02-15 07:00:00+00:00    569459   1294536"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a random sample of data\n",
    "sample = df.sample(n=100)\n",
    "sample.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "Parser Error station_name <class 'ValueError'>\n",
      "object\n",
      "Parser Error booth_name <class 'ValueError'>\n",
      "datetime64[ns, UTC]\n",
      "Int64\n",
      "Int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3670/1588983481.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(sample_data)\n",
      "/tmp/ipykernel_3670/1588983481.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(sample_data)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dimension</th>\n",
       "      <th>data_type</th>\n",
       "      <th>measure</th>\n",
       "      <th>datetime_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>station_name</th>\n",
       "      <td>True</td>\n",
       "      <td>object</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>booth_name</th>\n",
       "      <td>True</td>\n",
       "      <td>object</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_dt</th>\n",
       "      <td>True</td>\n",
       "      <td>datetime64[ns, UTC]</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entries</th>\n",
       "      <td>None</td>\n",
       "      <td>Int64</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exits</th>\n",
       "      <td>None</td>\n",
       "      <td>Int64</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dimension            data_type measure datetime_dimension\n",
       "station_name      True               object   False              False\n",
       "booth_name        True               object   False              False\n",
       "created_dt        True  datetime64[ns, UTC]    None               True\n",
       "entries           None                Int64    True               None\n",
       "exits             None                Int64    True               None"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_datetime(df, col, sample_size=10):\n",
    "  \"\"\"\n",
    "  Checks if a column in a DataFrame potentially contains datetime data.\n",
    "\n",
    "  Args:\n",
    "      df (pandas.DataFrame): The DataFrame containing the column to analyze.\n",
    "      col (str): The name of the column to check.\n",
    "      sample_size (int, optional): The number of rows to use for sample data analysis. Defaults to 10.\n",
    "\n",
    "  Returns:\n",
    "      bool: True if the column potentially contains datetime data, False otherwise.\n",
    "  \"\"\"\n",
    "\n",
    "  # Get data type\n",
    "  data_type = df[col].dtype\n",
    "  value = False\n",
    "\n",
    "  if data_type in [object, str]:    \n",
    "    try:\n",
    "      # Attempt to convert a sample of the column to datetime\n",
    "      sample_data = df[col].head(sample_size)\n",
    "      pd.to_datetime(sample_data) \n",
    "      value = True      \n",
    "    except (pd.errors.ParserError, ValueError):\n",
    "      # Conversion failed, not likely datetime\n",
    "      print(f\"Parser Error {col} {ValueError}\")\n",
    "  \n",
    "  return value\n",
    "\n",
    "\n",
    "def describe_dataframe(df):\n",
    "  \"\"\"\n",
    "  Analyzes a pandas DataFrame and provides a description of columns.\n",
    "\n",
    "  Args:\n",
    "      df (pandas.DataFrame): The DataFrame to analyze.\n",
    "\n",
    "  Returns:\n",
    "      dict: A dictionary where keys are column names and values are dictionaries\n",
    "          containing descriptions of 'dimension', 'data_type', 'measure',\n",
    "          and 'datetime_dimension'.\n",
    "  \"\"\"\n",
    "\n",
    "  # Initialize an empty dictionary to store column descriptions\n",
    "  column_descriptions = {}\n",
    "\n",
    "  # Iterate through each column\n",
    "  for col in df.columns:\n",
    "    # Get data type\n",
    "    data_type = df[col].dtype\n",
    "    print(data_type)\n",
    "    dimension = None\n",
    "    datetime_dimension = None  # Not a datetime dimension\n",
    "    measure = None\n",
    "\n",
    "    # Analyze potential dimension vs. measure based on data type and heuristics   \n",
    "    if 'datetime' in data_type.name:\n",
    "      dimension = True\n",
    "      datetime_dimension = True  # Not a datetime dimension\n",
    "    elif data_type in [object, str]:\n",
    "      # Likely a dimension if it contains words or non-numeric characters\n",
    "      dimension = any(char.isalpha() for char in col) or not all(char.isdigit() for char in col.split('-'))      \n",
    "      datetime_dimension = is_datetime(df,col)          \n",
    "      measure = not dimension\n",
    "      # print(f'{col} dim: {dimension} or mea: {measure}')      \n",
    "    else:\n",
    "      # Numeric data type, potential measure      \n",
    "      measure = True      \n",
    "\n",
    "    # Store the description for this column\n",
    "    column_descriptions[col] = {\n",
    "        'dimension': dimension,\n",
    "        'data_type': data_type,\n",
    "        'measure': measure,\n",
    "        'datetime_dimension': datetime_dimension\n",
    "    }\n",
    "\n",
    "  return column_descriptions\n",
    "\n",
    "profiling_results = describe_dataframe(sample)\n",
    "profiling_df = pd.DataFrame.from_dict(profiling_results, orient='index')\n",
    "profiling_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing\n",
    "> This is a step that should be done even with trusted data sources. Find bad data, outliers and set the correct data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values in each column\n",
    "null_counts = df.isnull().sum()\n",
    "null_counts.head()\n",
    "\n",
    "# fill null values with a specific value\n",
    "df = df.fillna(0)\n",
    "\n",
    "# cast a column to a specific data type\n",
    "df['created_dt'] = pd.to_datetime(df['created_dt'])\n",
    "\n",
    "# get the numeric col names and cast them to int\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "df[numeric_cols] = df[numeric_cols].astype(int)\n",
    "\n",
    "# Rename all columns to lowercase\n",
    "df.columns = [col.lower() for col in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find outliers\n",
    "\n",
    "> Outliers are values that are notably different from the other data points in terms of magnitude or distribution\n",
    "\n",
    "Based on the z-score threshold, this analysis identifies significant deviations from the average for \"entries\" and \"exits\" at specific stations. This information can be helpful for further investigation or outlier removal, depending on your needs. Holidays that can cause this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 entries  exits\n",
      "station_name                   \n",
      "1 AV                  12     12\n",
      "103 ST                 0     18\n",
      "103 ST-CORONA          0      0\n",
      "104 ST                 0      0\n",
      "110 ST                 0      0\n",
      "...                  ...    ...\n",
      "WOODLAWN               0      0\n",
      "WORLD TRADE CTR       12     12\n",
      "WTC-CORTLANDT         18     24\n",
      "YORK ST                0      0\n",
      "ZEREGA AV              0      0\n",
      "\n",
      "[378 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# measure outliers for entries and exits\n",
    "# Calculate z-scores within each station group\n",
    "z_scores = df.groupby('station_name')[numeric_cols] \\\n",
    "        .transform(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "# Set a threshold for outliers\n",
    "threshold = 3\n",
    "\n",
    "# Identify outliers based on z-scores within each station\n",
    "outliers = (z_scores.abs() > threshold)\n",
    "\n",
    "# Print the count of outliers for each station\n",
    "outliers_by_station = outliers.groupby(df['station_name']).sum()\n",
    "print(outliers_by_station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features ['station_name', 'booth_name']\n",
      "Numerical features ['entries', 'exits']\n"
     ]
    }
   ],
   "source": [
    "# get a list of numeric features\n",
    "features_numeric = list(df.select_dtypes(include=[np.number]).columns)\n",
    "\n",
    "# get a list of object features and exclude the target feature 'heartdisease'\n",
    "features_category = list(df.select_dtypes(include=['object']).columns)\n",
    "\n",
    "print('Categorical features',features_category)\n",
    "print('Numerical features',features_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   station_name booth_name                created_dt  entries     exits  \\\n",
      "0  ASTORIA BLVD       R514 2024-02-20 03:00:00+00:00  7112558  12965593   \n",
      "1  ASTORIA BLVD       R514 2024-02-20 19:00:00+00:00  7112994  12966073   \n",
      "2  ASTORIA BLVD       R514 2024-02-20 15:00:00+00:00  7112924  12965738   \n",
      "3  ASTORIA BLVD       R514 2024-02-20 23:00:00+00:00  7113012  12966274   \n",
      "4  ASTORIA BLVD       R514 2024-02-20 07:00:00+00:00  7112603  12965603   \n",
      "\n",
      "  day_of_week  hour_of_day    time_window  \n",
      "0     Tuesday            3       midnight  \n",
      "1     Tuesday           19          night  \n",
      "2     Tuesday           15      afternoon  \n",
      "3     Tuesday           23     late-night  \n",
      "4     Tuesday            7  early-morning  \n"
     ]
    }
   ],
   "source": [
    "# Derive new features\n",
    "df['day_of_week'] = df['created_dt'].dt.day_name()\n",
    "df['hour_of_day'] = df['created_dt'].dt.hour\n",
    "\n",
    "# Define time window thresholds (adjust based on your data and analysis)\n",
    "time_slots = {\n",
    "    'midnight': (0,3),\n",
    "    'early-morning': (4,7),\n",
    "    'morning': (8, 11),\n",
    "    'afternoon': (12, 15),\n",
    "    'night': (16, 20),\n",
    "    'late-night': (21, 23)\n",
    "}\n",
    "\n",
    "def define_time_window(hour, time_slots):\n",
    "  \"\"\"\n",
    "  This function categorizes a given hour into a time slot based on the provided definitions.\n",
    "\n",
    "  Args:\n",
    "      hour (int): The hour of the day (0-23).\n",
    "      time_slots (dict): A dictionary mapping time slot names to tuples representing start and end hours (inclusive).\n",
    "\n",
    "  Returns:\n",
    "      str: The time slot name corresponding to the provided hour.\n",
    "  \"\"\"\n",
    "\n",
    "  for time_slot_name, (start, end) in time_slots.items():\n",
    "    if start <= hour <= end:\n",
    "      return time_slot_name\n",
    "  # Handle cases outside defined time slots (optional)\n",
    "  raise ValueError(f\"Hour {hour} is outside defined time slots\")  # Raise an error for unexpected hours\n",
    "\n",
    "# Create time window feature\n",
    "df['time_window'] = df['hour_of_day'].apply(define_time_window, time_slots=time_slots)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 378 entries, 1 AV to ZEREGA AV\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mean          378 non-null    Float64\n",
      " 1   std           378 non-null    Float64\n",
      " 2   low_entries   378 non-null    Float64\n",
      " 3   high_entries  378 non-null    Float64\n",
      "dtypes: Float64(4)\n",
      "memory usage: 16.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate mean and standard deviation of values grouped by station\n",
    "def calculate_stats(values, label):\n",
    "  mean_values = values.mean()\n",
    "  std_values = values.std()\n",
    "  low_values = mean_values - std_values\n",
    "  high_values = mean_values + std_values\n",
    "  df = pd.DataFrame({ f'low_{label}': [low_values], f'high_{label}': [high_values]})\n",
    "  return df\n",
    "\n",
    "\n",
    "# def calculate_stats_per_station(df, label_column, value_column):\n",
    "#     stats_per_station = {}\n",
    "#     for station, data in df.groupby(label_column):\n",
    "#         values = data[value_column]\n",
    "#         if not values.empty:\n",
    "#             mean_values = values.mean()\n",
    "#             std_values = values.std()\n",
    "#             low_values = mean_values - std_values\n",
    "#             high_values = mean_values + std_values\n",
    "#             stats_per_station[station] = {'mean': mean_values, 'std': std_values, 'low': low_values, 'high': high_values}\n",
    "#     return pd.DataFrame(stats_per_station)\n",
    "\n",
    "def calculate_stats_per_station(df, label_column, value_column):\n",
    "    # Group data by station and calculate statistics\n",
    "    stats_per_station = df.groupby(label_column)[value_column].agg(['mean', 'std'])\n",
    "    # Calculate low and high values\n",
    "    low_label = f'low_{value_column}'\n",
    "    high_label = f'high_{value_column}'\n",
    "    stats_per_station[low_label] = stats_per_station['mean'] - stats_per_station['std']\n",
    "    stats_per_station[high_label] = stats_per_station['mean'] + stats_per_station['std']\n",
    "    # Unstack the DataFrame to move 'low' and 'high' to columns\n",
    "    stats_per_station = stats_per_station.unstack().swaplevel().unstack()\n",
    "    return stats_per_station\n",
    "\n",
    "# # Print the result (unstacking for clarity)\n",
    "# stats = (df.groupby('station_name')['entries']\n",
    "#          .apply(calculate_stats, label='entries')\n",
    "#          .reset_index()).unstack()\n",
    "\n",
    "stats = calculate_stats_per_station(df, 'station_name', 'entries')\n",
    "\n",
    "print(stats.info())\n",
    "\n",
    "# Define a function to categorize foot traffic (using station-specific stats)\n",
    "def define_foot_traffic(values, low_threshold, high_threshold):\n",
    "  try:\n",
    "    if values < low_threshold:\n",
    "      return 'Low'\n",
    "    elif values > high_threshold:\n",
    "      return 'High'\n",
    "    else:\n",
    "      return 'Medium'    \n",
    "  except KeyError:\n",
    "        # Handle the case when station-specific stats are not available\n",
    "        # Set default thresholds or return a specific value\n",
    "    return 'Not Available'\n",
    "\n",
    "# Create a new column 'foot_traffic'\n",
    "# df['foot_traffic'] = df.apply(lambda row: define_foot_traffic(row['entries'], \n",
    "#                                                              stats.loc[(row['station_name'], 'low_entries')],\n",
    "#                                                              stats.loc[(row['station_name'], 'high_entries')]), \n",
    "#                                axis=1)\n",
    "\n",
    "# # Print the DataFrame with foot traffic categories\n",
    "# print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
